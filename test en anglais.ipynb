{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 09:59:56.004544: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 09:59:56.127910: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 09:59:56.164369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 09:59:56.425739: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-17 09:59:58.070891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear all, I hope this email finds you well. I am writing to invite you all to a meeting on Monday, 23 September 2024 a 10h00 in the white room. The agenda includes the following topics: 1. To solve the bug that occurred last week 2. To learn about our new priorities 3. To learn more about the client BricoRigolo. We are looking forward to having you join us for this very important meeting. Thank you. Best regards, [Your Name]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Définir le prompt pour la génération de texte\n",
    "prompt = \"Ecrit moi un email en français pour inviter mon équipe à une réunion qui aura lieu lundi 23 septembre 2024 à 10h00 dans la salle blanche. L'ordre du jour est : -1. Comment résoudre le bug de la semaine dernière -2. Quelles sont les nouvelles priorités -3. Pourquoi le client BricoRigolo nous a laché ?\"\n",
    "\n",
    "# Charger le modèle de Hugging Face\n",
    "model = pipeline(model=\"declare-lab/flan-alpaca-gpt4-xl\")\n",
    "\n",
    "# Générer du texte à partir du prompt\n",
    "output = model(prompt, max_length=2000, do_sample=True)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(output[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
